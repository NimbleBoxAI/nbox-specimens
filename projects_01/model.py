import torch
from torch.nn import Linear, Sequential, LayerNorm

# This function builds a simple multi-layer perceptron (MLP) model. The
# model consists of two linear layers with layer normalization applied
# after each layer. The model is parametrized by the input dimension
# (`in_dim`), output dimension (`out_dim`), hidden dimension (`h_dim`),
# and number of layers (`n_layers`). The output of the model is the
# output of the final linear layer.

def get_model(
  in_dim: int,
  out_dim: int,
  h_dim: int = 64,
  n_layers: int = 2,
):
  """Build a simple MLP model."""
  layers = []
  for i in range(n_layers):
    layers.append(Linear(in_dim, h_dim))
    layers.append(LayerNorm(h_dim))
    in_dim = h_dim
  layers.append(Linear(h_dim, out_dim))
  return Sequential(*layers)


# This code generates a random dataset of the specified shape, and returns it in batches
# of the specified batch size.
# The dataset is generated by creating a number of classes equal to the last dimension
# of the shape, and then creating a normal distribution (with a mean of the class number
# and a standard deviation of 1) for each class. The data is then shuffled, and the
# batches are yielded.

def create_data(shape = (1000, 5)):
  n_classes = shape[-1]
  data = torch.cat(
    [torch.normal(i, 1, (shape[0]//n_classes, shape[1])) for i in range(n_classes)],
    dim = 0
  ).tolist()
  labels = torch.cat(
    [torch.full((shape[0]//n_classes,), i) for i in range(n_classes)],
    dim = 0
  ).tolist()

  # Shuffle the data
  full = torch.tensor([[*d, l] for d, l in zip(data, labels)])[torch.randperm(shape[0])]
  data = full[:, :-1]
  labels = full[:, -1]
  labels = labels.long()

  return data, labels

def data_iterator(
  batch_size: int,
  shape = (1000, 5),
  repeat: bool = False,
  drop_last: bool = True,
):
  # every time the iterator is called, it will create a new dataset, however, the
  # since the data is guassian distributed, the data will more of the same
  data, labels = create_data(shape)

  # Yield the data
  for i in range(0, shape[0], batch_size):
    if i + batch_size >= shape[0] and drop_last:
      break
    yield {
      "input": data[i:i+batch_size],
      "labels": labels[i:i+batch_size]
    }
  if repeat:
    yield from create_data(batch_size, shape, repeat, drop_last)

def get_data(
  data: torch.Tensor,
  labels: torch.Tensor,
  batch_size: int,
  repeat: bool = False,
  drop_last: bool = True,
):
  total_items = data.shape[0]
  for i in range(0, total_items, batch_size):
    if i + batch_size >= total_items and drop_last:
      break
    yield {
      "input": data[i:i+batch_size],
      "labels": labels[i:i+batch_size]
    }
  if repeat:
    yield from get_data(data, labels, batch_size, repeat, drop_last)
